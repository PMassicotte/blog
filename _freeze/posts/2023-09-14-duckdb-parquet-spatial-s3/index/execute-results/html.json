{
  "hash": "44d320ddb47fb3277a713393aacf9ebf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Unlocking Cloud Data: A Step-by-Step Guide to Reading and Transforming Spatial Data with DuckDB'\nauthor: 'Philippe Massicotte'\ndate: '2023-09-14'\ncategories: [R, Geospatial, DuckDB, Spatial, Simple Features, Parquet]\n\n# The preview file needs to be named preview.png\n# mogrify -format png preview.jpg\n# https://quarto.org/docs/websites/website-tools.html#preview-images\nimage: 'https://repository-images.githubusercontent.com/138754790/fdc92700-357b-11eb-9761-54b3c051137c'\neditor_options:\n  chunk_output_type: console\ncitation: true\n---\n\n\n\n\n\n\n\n\nIn this blog post, I will show you how to read and transform spatial data hosted in the cloud with [DuckDB](https://duckdb.org/)^[DuckDB preview image: https://archive.org/details/github.com-duckdb-duckdb_-_2022-08-11_05-54-07]. I will use the [nycflights13](https://github.com/tidyverse/nycflights13), a popular dataset for learning [data science](https://r4ds.hadley.nz/). I will also use the [sf](https://github.com/r-spatial/sf/) package to manipulate spatial data. We will first start our journey by using DuckDB to read tabular data from parquet files from an online repository. Then with [dbplyr](https://github.com/tidyverse/dbplyr/) as a backbend, we will query the data. Then, with the help of the [DuckDB spatial extension](https://duckdb.org/docs/extensions/spatial), I will introduce how we can do geospatial processing within DuckDB and sf.\n\n## What is DuckDB?\n\nDuckDB is an embeddable SQL OLAP database management system designed for efficient data querying and manipulation. It excels in processing large datasets swiftly and is particularly adept at handling complex analytical tasks while offering the flexibility to seamlessly integrate with various data [sources and formats](https://duckdb.org/docs/archive/0.8.1/data/overview). DuckDB also comes with a set of [extensions](https://duckdb.org/docs/extensions/overview):\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"idzhvggdfe\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#idzhvggdfe table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#idzhvggdfe thead, #idzhvggdfe tbody, #idzhvggdfe tfoot, #idzhvggdfe tr, #idzhvggdfe td, #idzhvggdfe th {\n  border-style: none;\n}\n\n#idzhvggdfe p {\n  margin: 0;\n  padding: 0;\n}\n\n#idzhvggdfe .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#idzhvggdfe .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#idzhvggdfe .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#idzhvggdfe .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#idzhvggdfe .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#idzhvggdfe .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#idzhvggdfe .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#idzhvggdfe .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#idzhvggdfe .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#idzhvggdfe .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#idzhvggdfe .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#idzhvggdfe .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#idzhvggdfe .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#idzhvggdfe .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#idzhvggdfe .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#idzhvggdfe .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#idzhvggdfe .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#idzhvggdfe .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#idzhvggdfe .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#idzhvggdfe .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#idzhvggdfe .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#idzhvggdfe .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#idzhvggdfe .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#idzhvggdfe .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#idzhvggdfe .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#idzhvggdfe .gt_left {\n  text-align: left;\n}\n\n#idzhvggdfe .gt_center {\n  text-align: center;\n}\n\n#idzhvggdfe .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#idzhvggdfe .gt_font_normal {\n  font-weight: normal;\n}\n\n#idzhvggdfe .gt_font_bold {\n  font-weight: bold;\n}\n\n#idzhvggdfe .gt_font_italic {\n  font-style: italic;\n}\n\n#idzhvggdfe .gt_super {\n  font-size: 65%;\n}\n\n#idzhvggdfe .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#idzhvggdfe .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#idzhvggdfe .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#idzhvggdfe .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#idzhvggdfe .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#idzhvggdfe .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#idzhvggdfe .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"extension_name\">extension_name</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"loaded\">loaded</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"installed\">installed</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"aliases\">aliases</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"extension_version\">extension_version</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">arrow</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">A zero-copy data integration between Apache Arrow and DuckDB</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">autocomplete</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for autocomplete in the shell</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">aws</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Provides features that depend on the AWS SDK</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">azure</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds a filesystem abstraction for Azure blob storage to DuckDB</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">excel</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for Excel-like format strings</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">fts</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for Full-Text Search Indexes</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">httpfs</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">TRUE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for reading and writing files over a HTTP(S) connection</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\">http, https, s3</td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">iceberg</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for Apache Iceberg</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">icu</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for time zones and collations using the ICU library</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">inet</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for IP-related data types and functions</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">jemalloc</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Overwrites system allocator with JEMalloc</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">json</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for JSON operations</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">motherduck</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Enables motherduck integration with the system</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\">md</td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">mysql_scanner</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for connecting to a MySQL database</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\">mysql</td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">parquet</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">TRUE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">TRUE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for reading and writing parquet files</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">postgres_scanner</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for connecting to a Postgres database</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\">postgres</td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">spatial</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">TRUE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Geospatial extension that adds support for working with spatial data and functions</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">sqlite_scanner</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for reading and writing SQLite database files</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\">sqlite, sqlite3</td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">substrait</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds support for the Substrait integration</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">tpcds</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds TPC-DS data generation and query support</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n    <tr><td headers=\"extension_name\" class=\"gt_row gt_left\">tpch</td>\n<td headers=\"loaded\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"installed\" class=\"gt_row gt_center\">FALSE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Adds TPC-H data generation and query support</td>\n<td headers=\"aliases\" class=\"gt_row gt_center\"></td>\n<td headers=\"extension_version\" class=\"gt_row gt_right\"></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n![These ducklings hatched the same morning as this walk. They walked from their nest to the nearby pond, across neighbourhood streets](img/img1.png){width=85%}\n\n<center>Photo by <a href=\"https://unsplash.com/@tchompalov?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Vlad Tchompalov</a> on <a href=\"https://unsplash.com/photos/wt5Y8VY_0bA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a></center>\n\n## Create a DuckDB remote connection\n\nFor the following example, I will work with the nycflights13 data saved in parquet file format and hosted inside S3 buckets. I will use the [httpfs](https://duckdb.org/docs/extensions/httpfs) extension to read the data. The httpfs extension allows DuckDB to read data from remote HTTP(S) sources which is exactly what we need here to read that data from the cloud.\n\nThe first thing I need to do is to create a DuckDB connection using `DBI::dbConnect()` and install the httpfs extension and load it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(duckdb)\nlibrary(DBI)\n\n# Create a connection\nconn <- DBI::dbConnect(duckdb())\n\n# Install the httpfs extension and load it\ndbExecute(conn, \"INSTALL httpfs; LOAD httpfs;\")\n#> [1] 0\n```\n:::\n\n\nNow that we have a connection, we can start exploring the data! All tables are stored in [parquet files](https://en.wikipedia.org/wiki/Apache_Parquet) and hosted in s3 buckets. Here are the links to the data:\n\n- [airlines](https://nycflights13.s3.valeria.science/airlines/20230913T174717Z-23aeb/airlines.parquet)\n- [airports](https://nycflights13.s3.valeria.science/airports/20230913T174717Z-ec372/airports.parquet)^[Note that the airports table had positive longitudes. It seems that they should all be negative, so I corrected them.]\n- [flights](https://nycflights13.s3.valeria.science/flights/20230913T174716Z-3899c/flights.parquet)\n- [planes](https://nycflights13.s3.valeria.science/planes/20230913T174717Z-b5438/planes.parquet)\n- [weather](https://nycflights13.s3.valeria.science/weather/20230913T174717Z-01531/weather.parquet)\n\n![I'm @eodiin on Instagram](img/img2.png){width=85%}\n\n<center>Photo by <a href=\"https://unsplash.com/@odiin?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Erik Odiin</a> on <a href=\"https://unsplash.com/photos/jbQvJx2EWnU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a></center>\n\n<br>\n\nI will start by reading the `flights` table using the [SQL](https://duckdb.org/docs/sql/introduction) syntax. To do so, I will use the `read_parquet()` function from DuckDB to read the parquet file and return a DuckDB table. Then, I will use the `CREATE OR REPLACE TABLE` statement to create a new table called `flights` and store the data returned by `read_parquet()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery <- paste(\n  \"CREATE OR REPLACE TABLE flights as SELECT * FROM\",\n  \"read_parquet('https://nycflights13.s3.valeria.science/flights/20230913T174716Z-3899c/flights.parquet')\"\n)\n\ndbExecute(conn, query)\n#> [1] 336776\n```\n:::\n\n\nWe can verify that the table was created by using the `SHOW ALL TABLES` statement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"SHOW ALL TABLES;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 1 Ã— 6\n#>   database schema name    column_names column_types temporary\n#>   <chr>    <chr>  <chr>   <list>       <list>       <lgl>    \n#> 1 memory   main   flights <chr [19]>   <chr [19]>   FALSE\n```\n:::\n\n\nWe can further explore the table by using the following statements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"FROM flights LIMIT 10;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 10 Ã— 19\n#>     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#>    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n#>  1  2013     1     1      517            515         2      830            819\n#>  2  2013     1     1      533            529         4      850            830\n#>  3  2013     1     1      542            540         2      923            850\n#>  4  2013     1     1      544            545        -1     1004           1022\n#>  5  2013     1     1      554            600        -6      812            837\n#>  6  2013     1     1      554            558        -4      740            728\n#>  7  2013     1     1      555            600        -5      913            854\n#>  8  2013     1     1      557            600        -3      709            723\n#>  9  2013     1     1      557            600        -3      838            846\n#> 10  2013     1     1      558            600        -2      753            745\n#> # â„¹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\ndbSendQuery(conn, \"SHOW flights;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 19 Ã— 6\n#>    column_name    column_type              null  key   default extra\n#>    <chr>          <chr>                    <chr> <chr> <chr>   <chr>\n#>  1 year           INTEGER                  YES   <NA>  <NA>    <NA> \n#>  2 month          INTEGER                  YES   <NA>  <NA>    <NA> \n#>  3 day            INTEGER                  YES   <NA>  <NA>    <NA> \n#>  4 dep_time       INTEGER                  YES   <NA>  <NA>    <NA> \n#>  5 sched_dep_time INTEGER                  YES   <NA>  <NA>    <NA> \n#>  6 dep_delay      DOUBLE                   YES   <NA>  <NA>    <NA> \n#>  7 arr_time       INTEGER                  YES   <NA>  <NA>    <NA> \n#>  8 sched_arr_time INTEGER                  YES   <NA>  <NA>    <NA> \n#>  9 arr_delay      DOUBLE                   YES   <NA>  <NA>    <NA> \n#> 10 carrier        VARCHAR                  YES   <NA>  <NA>    <NA> \n#> 11 flight         INTEGER                  YES   <NA>  <NA>    <NA> \n#> 12 tailnum        VARCHAR                  YES   <NA>  <NA>    <NA> \n#> 13 origin         VARCHAR                  YES   <NA>  <NA>    <NA> \n#> 14 dest           VARCHAR                  YES   <NA>  <NA>    <NA> \n#> 15 air_time       DOUBLE                   YES   <NA>  <NA>    <NA> \n#> 16 distance       DOUBLE                   YES   <NA>  <NA>    <NA> \n#> 17 hour           DOUBLE                   YES   <NA>  <NA>    <NA> \n#> 18 minute         DOUBLE                   YES   <NA>  <NA>    <NA> \n#> 19 time_hour      TIMESTAMP WITH TIME ZONE YES   <NA>  <NA>    <NA>\n\ndbSendQuery(conn, \"SUMMARIZE flights;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 19 Ã— 12\n#>    column_name    column_type  min   max   approx_unique avg   std   q25   q50  \n#>    <chr>          <chr>        <chr> <chr>         <dbl> <chr> <chr> <chr> <chr>\n#>  1 year           INTEGER      2013  2013              1 2013â€¦ 0.0   2013  2013 \n#>  2 month          INTEGER      1     12               12 6.54â€¦ 3.41â€¦ 4     7    \n#>  3 day            INTEGER      1     31               31 15.7â€¦ 8.76â€¦ 8     16   \n#>  4 dep_time       INTEGER      1     2400           1317 1349â€¦ 488.â€¦ 905   1382 \n#>  5 sched_dep_time INTEGER      106   2359           1023 1344â€¦ 467.â€¦ 909   1377 \n#>  6 dep_delay      DOUBLE       -43.0 1301â€¦           533 12.6â€¦ 40.2â€¦ -5.0  -1.5â€¦\n#>  7 arr_time       INTEGER      1     2400           1418 1502â€¦ 533.â€¦ 1098  1535 \n#>  8 sched_arr_time INTEGER      1     2359           1155 1536â€¦ 497.â€¦ 1124  1570 \n#>  9 arr_delay      DOUBLE       -86.0 1272â€¦           581 6.89â€¦ 44.6â€¦ -17.â€¦ -5.0â€¦\n#> 10 carrier        VARCHAR      9E    YV               16 <NA>  <NA>  <NA>  <NA> \n#> 11 flight         INTEGER      1     8500           3908 1971â€¦ 1632â€¦ 557   1497 \n#> 12 tailnum        VARCHAR      D942â€¦ N9EAâ€¦          4005 <NA>  <NA>  <NA>  <NA> \n#> 13 origin         VARCHAR      EWR   LGA               3 <NA>  <NA>  <NA>  <NA> \n#> 14 dest           VARCHAR      ABQ   XNA             105 <NA>  <NA>  <NA>  <NA> \n#> 15 air_time       DOUBLE       20.0  695.0           516 150.â€¦ 93.6â€¦ 82.1â€¦ 129.â€¦\n#> 16 distance       DOUBLE       17.0  4983â€¦           210 1039â€¦ 733.â€¦ 508.â€¦ 865.â€¦\n#> 17 hour           DOUBLE       1.0   23.0             20 13.1â€¦ 4.66â€¦ 8.99â€¦ 13.4â€¦\n#> 18 minute         DOUBLE       0.0   59.0             60 26.2â€¦ 19.3â€¦ 7.98â€¦ 28.9â€¦\n#> 19 time_hour      TIMESTAMP Wâ€¦ 2013â€¦ 2014â€¦          6865 <NA>  <NA>  <NA>  <NA> \n#> # â„¹ 3 more variables: q75 <chr>, count <dbl>, null_percentage <dbl>\n```\n:::\n\n\nGood, we now have created a table, we can start querying it. Let's start by calculating the average delay per destination. I will show how to do it with both DuckDB and R.\n\n## Data wrangling using DuckDB\n\nI will use the `GROUP BY` statement to group the data by destination and then use the `AVG()` function to calculate the average delay and finally order the results with the `ORDER BY` clause.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1 <- dbSendQuery(\n  conn,\n  \"SELECT dest, AVG(arr_delay) AS delay, COUNT(*) AS n\n  FROM flights GROUP BY dest ORDER BY delay DESC;\"\n) |>\n  dbFetch() |>\n  as_tibble()\n\ndf1\n#> # A tibble: 105 Ã— 3\n#>    dest   delay     n\n#>    <chr>  <dbl> <dbl>\n#>  1 CAE   41.764   116\n#>  2 TUL   33.660   315\n#>  3 OKC   30.619   346\n#>  4 JAC   28.095    25\n#>  5 TYS   24.069   631\n#>  6 MSN   20.196   572\n#>  7 RIC   20.111  2454\n#>  8 CAK   19.698   864\n#>  9 DSM   19.006   569\n#> 10 GRR   18.190   765\n#> # â„¹ 95 more rows\n```\n:::\n\n\n## Data wrangling using dbplyr\n\nIf you prefer the syntax of [dplyr](https://dplyr.tidyverse.org/) syntax, you can use it to query DuckDB. First, we need to pull the data using the `tbl()` [function](https://dbplyr.tidyverse.org/reference/tbl.src_dbi.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(conn, \"flights\")\n#> # Source:   table<flights> [?? x 19]\n#> # Database: DuckDB v0.10.2 [unknown@Linux 6.5.0-28-generic:R 4.4.0/:memory:]\n#>     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#>    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n#>  1  2013     1     1      517            515         2      830            819\n#>  2  2013     1     1      533            529         4      850            830\n#>  3  2013     1     1      542            540         2      923            850\n#>  4  2013     1     1      544            545        -1     1004           1022\n#>  5  2013     1     1      554            600        -6      812            837\n#>  6  2013     1     1      554            558        -4      740            728\n#>  7  2013     1     1      555            600        -5      913            854\n#>  8  2013     1     1      557            600        -3      709            723\n#>  9  2013     1     1      557            600        -3      838            846\n#> 10  2013     1     1      558            600        -2      753            745\n#> # â„¹ more rows\n#> # â„¹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n\n\nThis gives us something to work with using the `dplyr` syntax. We can now use the `group_by()` function to group the data by destination and then use the `summarize()` function to calculate the average delay and the number of flights per destination. Finally, we can use the `arrange()` function to order the results by delay. But before we get the results, we can show what is the SQL query that was generated with the `show_query()` function from the [dbplyr](https://dbplyr.tidyverse.org/articles/sql.html) package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(conn, \"flights\") |>\n  group_by(dest) |>\n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) |>\n  arrange(desc(delay)) |>\n  show_query()\n#> <SQL>\n#> SELECT dest, COUNT(*) AS n, AVG(arr_delay) AS delay\n#> FROM flights\n#> GROUP BY dest\n#> ORDER BY delay DESC\n```\n:::\n\n\nNote that it looks pretty similar to the SQL query we wrote earlier. Now, we can get the results by using the `collect()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf2 <- tbl(conn, \"flights\") |>\n  group_by(dest) |>\n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  ) |>\n  arrange(desc(delay)) |>\n  collect()\n\ndf2\n#> # A tibble: 105 Ã— 3\n#>    dest   delay     n\n#>    <chr>  <dbl> <dbl>\n#>  1 CAE   41.764   116\n#>  2 TUL   33.660   315\n#>  3 OKC   30.619   346\n#>  4 JAC   28.095    25\n#>  5 TYS   24.069   631\n#>  6 MSN   20.196   572\n#>  7 RIC   20.111  2454\n#>  8 CAK   19.698   864\n#>  9 DSM   19.006   569\n#> 10 GRR   18.190   765\n#> # â„¹ 95 more rows\n```\n:::\n\n\nWe can verify that both data frames are the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(df1, df2)\n#> [1] TRUE\n```\n:::\n\n\n### Create a local database\n\nUp to now, we have been working with an in-memory database. This means that once we close R, all the data will be lost. But what if we want to work with a local database? Well, it is pretty easy to do. We just need to specify the path to the database file when we create our connection. We can also specify if we want to create a read-only database or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"DBI\")\n\n# to start an in-memory database\ncon <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n\n# to use a database file (not shared between processes)\ncon <- dbConnect(duckdb::duckdb(), dbdir = \"my-db.duckdb\", read_only = FALSE)\n\n# to use a database file (shared between processes)\ncon <- dbConnect(duckdb::duckdb(), dbdir = \"my-db.duckdb\", read_only = TRUE)\n```\n:::\n\n\n## Let's go spatial ðŸš€ðŸš€ðŸš€\n\nIf you know the nycflights13 dataset, you have noticed that the `airports` table has a `lon` and `lat` columns. This means that we can use these columns to create a geometry column and do some geospatial processing. To do so, we will need to install the [spatial extension](https://duckdb.org/docs/extensions/spatial) and load it. But first, let's create the `airports` table as we did for the `flights` table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery <- paste(\n  \"CREATE OR REPLACE TABLE airports as SELECT * FROM\",\n  \"read_parquet('https://nycflights13.s3.valeria.science/airports/20230913T174717Z-ec372/airports.parquet')\"\n)\n\ndbExecute(conn, query)\n#> [1] 1458\n```\n:::\n\n\nWe can verify that we now have two tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"SHOW ALL TABLES;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 2 Ã— 6\n#>   database schema name     column_names column_types temporary\n#>   <chr>    <chr>  <chr>    <list>       <list>       <lgl>    \n#> 1 memory   main   airports <chr [8]>    <chr [8]>    FALSE    \n#> 2 memory   main   flights  <chr [19]>   <chr [19]>   FALSE\n```\n:::\n\n\nAnd also have a glimpse of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"SHOW airports;\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 8 Ã— 6\n#>   column_name column_type null  key   default extra\n#>   <chr>       <chr>       <chr> <chr> <chr>   <chr>\n#> 1 faa         VARCHAR     YES   <NA>  <NA>    <NA> \n#> 2 name        VARCHAR     YES   <NA>  <NA>    <NA> \n#> 3 lat         DOUBLE      YES   <NA>  <NA>    <NA> \n#> 4 lon         DOUBLE      YES   <NA>  <NA>    <NA> \n#> 5 alt         DOUBLE      YES   <NA>  <NA>    <NA> \n#> 6 tz          DOUBLE      YES   <NA>  <NA>    <NA> \n#> 7 dst         VARCHAR     YES   <NA>  <NA>    <NA> \n#> 8 tzone       VARCHAR     YES   <NA>  <NA>    <NA>\n\ndbSendQuery(conn, \"SHOW airports;\") |>\n  dbFetch()\n#>   column_name column_type null  key default extra\n#> 1         faa     VARCHAR  YES <NA>    <NA>  <NA>\n#> 2        name     VARCHAR  YES <NA>    <NA>  <NA>\n#> 3         lat      DOUBLE  YES <NA>    <NA>  <NA>\n#> 4         lon      DOUBLE  YES <NA>    <NA>  <NA>\n#> 5         alt      DOUBLE  YES <NA>    <NA>  <NA>\n#> 6          tz      DOUBLE  YES <NA>    <NA>  <NA>\n#> 7         dst     VARCHAR  YES <NA>    <NA>  <NA>\n#> 8       tzone     VARCHAR  YES <NA>    <NA>  <NA>\n```\n:::\n\n\nAt this point, this is a simple table with no geometry column. To create the geometry column, we first need to install the spatial extension and load it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(conn, \"INSTALL 'spatial'; LOAD 'spatial';\")\n#> [1] 0\n```\n:::\n\n\nThis is now the time to let the magic happen. I will create a new table `airports_sf` and use the `ST_asWKB()` function to create the `geometry` column. The `ST_asWKB()` function takes two arguments: the geometry type and the geometry column. In our case, we will use the `ST_Point()` function to create a point geometry from the `lon` and `lat` columns that are present in the `airports` table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Here I am creating the geometry column, looks like it worked.\ndbExecute(\n  conn,\n  \"CREATE OR REPLACE TABLE airports_sf AS SELECT *,\n  ST_asWKB(ST_Point(lon, lat)) as geometry, FROM airports;\"\n)\n#> [1] 1458\n```\n:::\n\n\nLooks like it worked! There is a `geometry` column in the `airports_sf` table. We can verify that by using the `SHOW airports_sf;` statement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"SHOW airports_sf;\") |>\n  dbFetch()\n#>   column_name column_type null  key default extra\n#> 1         faa     VARCHAR  YES <NA>    <NA>  <NA>\n#> 2        name     VARCHAR  YES <NA>    <NA>  <NA>\n#> 3         lat      DOUBLE  YES <NA>    <NA>  <NA>\n#> 4         lon      DOUBLE  YES <NA>    <NA>  <NA>\n#> 5         alt      DOUBLE  YES <NA>    <NA>  <NA>\n#> 6          tz      DOUBLE  YES <NA>    <NA>  <NA>\n#> 7         dst     VARCHAR  YES <NA>    <NA>  <NA>\n#> 8       tzone     VARCHAR  YES <NA>    <NA>  <NA>\n#> 9    geometry    WKB_BLOB  YES <NA>    <NA>  <NA>\n```\n:::\n\n\n### Querying spatial data\n\nWith the geometry created, we can now do some geospatial processing. Let's start by calculating the distance between the airports and a point located at longitude -100 and latitude 40. To do so, we will use the `ST_GeomFromWKB()` function to create a geometry from the geometry column. Finally, we will use the `ST_Distance()` function to calculate the distance between the airports and a point located at longitude -100 and latitude 40. We will order the results by decreasing distances. If we look at the [extension](https://duckdb.org/docs/extensions/spatial) documentation, we note that the `ST_Distance` function operates on two geometry. However, the geometry column is of type WKB (well-known binary) and need to be converted to `geom` with `ST_GeomFromWKB()`. Finally, we can use the `ST_Distance()` function to calculate the distance between the airports and a point located at longitude -100 and latitude 40. ^[Note that we are using lat/lon data for the calculation whereas a projected coordinate reference system would be better suited.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbSendQuery(conn, \"SELECT faa, name,\n  st_distance(ST_Transform(ST_GeomFromWKB(geometry), 'EPSG:4326', 'EPSG:4326'),\n  ST_Transform(ST_Point(-100, 40), 'EPSG:4326', 'EPSG:4326')) as dist from\n  airports_sf ORDER BY dist DESC\") |>\n  dbFetch() |>\n  as_tibble()\n#> # A tibble: 1,458 Ã— 3\n#>    faa   name                    dist\n#>    <chr> <chr>                  <dbl>\n#>  1 ADK   Adak Airport          77.561\n#>  2 GAM   Gambell Airport       75.568\n#>  3 AKB   Atka Airport          75.206\n#>  4 SYA   Eareckson As          75.196\n#>  5 SVA   Savoonga Airport      74.366\n#>  6 WAA   Wales Airport         72.756\n#>  7 TNC   Tin City LRRS Airport 72.573\n#>  8 PHO   Point Hope Airport    72.566\n#>  9 SNP   St Paul Island        72.289\n#> 10 LUR   Cape Lisburne Lrrs    72.141\n#> # â„¹ 1,448 more rows\n```\n:::\n\n\nWhat is nice, is that it is possible to use `st_read()` from `sf` to read the data directly from DuckDB. To do so, we need to specify the connection the query (which columns from the table we want) and the geometry column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n\nairports_sf <- st_read(\n  conn,\n  query = \"SELECT * FROM airports_sf;\",\n  geometry_column = \"geometry\"\n)\n\nairports_sf\n#> Simple feature collection with 1458 features and 8 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: -176.646 ymin: 19.72137 xmax: -42.89833 ymax: 72.27083\n#> CRS:           NA\n#> First 10 features:\n#>    faa                           name      lat        lon  alt tz dst\n#> 1  04G              Lansdowne Airport 41.13047  -80.61958 1044 -5   A\n#> 2  06A  Moton Field Municipal Airport 32.46057  -85.68003  264 -6   A\n#> 3  06C            Schaumburg Regional 41.98934  -88.10124  801 -6   A\n#> 4  06N                Randall Airport 41.43191  -74.39156  523 -5   A\n#> 5  09J          Jekyll Island Airport 31.07447  -81.42778   11 -5   A\n#> 6  0A9 Elizabethton Municipal Airport 36.37122  -82.17342 1593 -5   A\n#> 7  0G6        Williams County Airport 41.46731  -84.50678  730 -5   A\n#> 8  0G7  Finger Lakes Regional Airport 42.88356  -76.78123  492 -5   A\n#> 9  0P2   Shoestring Aviation Airfield 39.79482  -76.64719 1000 -5   U\n#> 10 0S9          Jefferson County Intl 48.05381 -122.81064  108 -8   A\n#>                  tzone                   geometry\n#> 1     America/New_York POINT (-80.61958 41.13047)\n#> 2      America/Chicago POINT (-85.68003 32.46057)\n#> 3      America/Chicago POINT (-88.10124 41.98934)\n#> 4     America/New_York POINT (-74.39156 41.43191)\n#> 5     America/New_York POINT (-81.42778 31.07447)\n#> 6     America/New_York POINT (-82.17342 36.37122)\n#> 7     America/New_York POINT (-84.50678 41.46731)\n#> 8     America/New_York POINT (-76.78123 42.88356)\n#> 9     America/New_York POINT (-76.64719 39.79482)\n#> 10 America/Los_Angeles POINT (-122.8106 48.05381)\n```\n:::\n\n\nNote that if you want to write the data to a local file without using, so we can reuse it later, you can use the `COPY` statement. Here I am writing the `airports_sf` table to a GeoJSON file. Note that I am using the `LAYER_CREATION_OPTIONS` to specify that I want to write the bounding box to the file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(conn, \"COPY  airports_sf TO '~/Desktop/airports_sf.geojson' WITH (FORMAT GDAL, DRIVER 'GeoJSON', LAYER_CREATION_OPTIONS 'WRITE_BBOX=YES')\")\n```\n:::\n\n\nWhile I am there, why not visualize the data?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rnaturalearth)\n\ndest_proj <- \"ESRI:102008\"\n\nusa <- ne_countries(\n  country = \"United States of America\",\n  returnclass = \"sf\"\n) |>\n  st_transform(dest_proj)\n\n\nairports_sf |>\n  st_set_crs(4326) |>\n  ggplot() +\n  geom_sf(data = usa) +\n  geom_sf(size = 0.25) +\n  geom_point(aes(x = -100, y = 40), size = 5, color = \"red\") +\n  coord_sf(crs = dest_proj) +\n  theme(\n    axis.title = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png)\n:::\n:::\n\n\nFinally, do not forget to close your connection!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbDisconnect(conn, disconnect = TRUE)\n```\n:::\n\n\n## Ressources\n\n- <https://duckdb.org/docs/extensions/spatial>\n- <https://duckdb.org/2023/04/28/spatial.html>\n- <https://tech.marksblogg.com/duckdb-gis-spatial-extension.html>\n- <https://youtu.be/ZX5FdqzGT1E>\n- <https://youtu.be/ljzpm3Mrw-I?list=PLIYcNkSjh-0ztvwoAp3GeW8HNSUSk_q3K>\n\n<details>\n  \n<summary>Session info</summary>\n\n\n::: {.cell}\n\n```\n#> â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#>  setting  value\n#>  version  R version 4.4.0 (2024-04-24)\n#>  os       Linux Mint 21.3\n#>  system   x86_64, linux-gnu\n#>  ui       X11\n#>  language en_CA:en\n#>  collate  en_CA.UTF-8\n#>  ctype    en_CA.UTF-8\n#>  tz       America/Montreal\n#>  date     2024-05-02\n#>  pandoc   2.9.2.1 @ /usr/bin/ (via rmarkdown)\n#> \n#> â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#>  ! package       * version date (UTC) lib source\n#>  P blob            1.2.4   2023-03-17 [?] RSPM\n#>  P cachem          1.0.8   2023-05-01 [?] RSPM\n#>  P class           7.3-22  2023-05-03 [?] CRAN (R 4.3.1)\n#>  P classInt        0.4-10  2023-09-05 [?] RSPM\n#>  P cli             3.6.2   2023-12-11 [?] RSPM\n#>  P codetools       0.2-19  2023-02-01 [?] CRAN (R 4.2.2)\n#>  P colorspace      2.1-0   2023-01-23 [?] RSPM\n#>  P DBI           * 1.2.2   2024-02-16 [?] RSPM\n#>  P dbplyr          2.5.0   2024-03-19 [?] RSPM\n#>  P devtools        2.4.5   2022-10-11 [?] RSPM (R 4.4.0)\n#>  P digest          0.6.35  2024-03-11 [?] RSPM\n#>  P dplyr         * 1.1.4   2023-11-17 [?] RSPM\n#>  P duckdb        * 0.10.2  2024-05-01 [?] CRAN (R 4.4.0)\n#>  P e1071           1.7-14  2023-12-06 [?] RSPM\n#>  P ellipsis        0.3.2   2021-04-29 [?] RSPM\n#>  P evaluate        0.23    2023-11-01 [?] RSPM\n#>  P extrafont       0.19    2023-01-18 [?] RSPM\n#>  P extrafontdb     1.0     2012-06-11 [?] RSPM\n#>  P fansi           1.0.6   2023-12-08 [?] RSPM\n#>  P farver          2.1.1   2022-07-06 [?] RSPM\n#>  P fastmap         1.1.1   2023-02-24 [?] RSPM\n#>  P forcats       * 1.0.0   2023-01-29 [?] RSPM\n#>  P fs              1.6.4   2024-04-25 [?] CRAN (R 4.4.0)\n#>  P generics        0.1.3   2022-07-05 [?] RSPM\n#>  P ggplot2       * 3.5.1   2024-04-23 [?] RSPM\n#>  P ggpmthemes    * 0.0.2   2024-04-25 [?] Github (pmassicotte/ggpmthemes@993d61e)\n#>  P glue            1.7.0   2024-01-09 [?] RSPM\n#>  P gt              0.10.1  2024-01-17 [?] RSPM\n#>  P gtable          0.3.5   2024-04-22 [?] RSPM\n#>  P hms             1.1.3   2023-03-21 [?] RSPM\n#>  P htmltools       0.5.8.1 2024-04-04 [?] RSPM\n#>  P htmlwidgets     1.6.4   2023-12-06 [?] RSPM\n#>  P httpuv          1.6.15  2024-03-26 [?] RSPM\n#>  P httr            1.4.7   2023-08-15 [?] RSPM\n#>  P jsonlite        1.8.8   2023-12-04 [?] RSPM\n#>  P KernSmooth      2.23-22 2023-07-10 [?] CRAN (R 4.3.1)\n#>  P knitr           1.46    2024-04-06 [?] RSPM\n#>  P later           1.3.2   2023-12-06 [?] RSPM\n#>  P lifecycle       1.0.4   2023-11-07 [?] RSPM\n#>  P lubridate     * 1.9.3   2023-09-27 [?] RSPM\n#>  P magrittr        2.0.3   2022-03-30 [?] RSPM\n#>  P memoise         2.0.1   2021-11-26 [?] RSPM\n#>  P mime            0.12    2021-09-28 [?] RSPM\n#>  P miniUI          0.1.1.1 2018-05-18 [?] RSPM (R 4.4.0)\n#>  P munsell         0.5.1   2024-04-01 [?] RSPM\n#>  P pillar          1.9.0   2023-03-22 [?] RSPM\n#>  P pkgbuild        1.4.4   2024-03-17 [?] RSPM (R 4.4.0)\n#>  P pkgconfig       2.0.3   2019-09-22 [?] RSPM\n#>  P pkgload         1.3.4   2024-01-16 [?] RSPM (R 4.4.0)\n#>  P processx        3.8.4   2024-03-16 [?] RSPM\n#>  P profvis         0.3.8   2023-05-02 [?] RSPM (R 4.4.0)\n#>  P promises        1.3.0   2024-04-05 [?] RSPM\n#>  P proxy           0.4-27  2022-06-09 [?] RSPM\n#>  P ps              1.7.6   2024-01-18 [?] RSPM\n#>  P purrr         * 1.0.2   2023-08-10 [?] RSPM\n#>  P quarto        * 1.4     2024-03-06 [?] RSPM\n#>  P R.cache         0.16.0  2022-07-21 [?] RSPM\n#>  P R.methodsS3     1.8.2   2022-06-13 [?] RSPM\n#>  P R.oo            1.26.0  2024-01-24 [?] RSPM\n#>  P R.utils         2.12.3  2023-11-18 [?] RSPM\n#>  P R6              2.5.1   2021-08-19 [?] RSPM\n#>  P Rcpp            1.0.12  2024-01-09 [?] RSPM\n#>  P readr         * 2.1.5   2024-01-10 [?] RSPM\n#>  P remotes         2.5.0   2024-03-17 [?] RSPM (R 4.4.0)\n#>  P renv            1.0.7   2024-04-11 [?] RSPM (R 4.4.0)\n#>  P rlang           1.1.3   2024-01-10 [?] RSPM\n#>  P rmarkdown       2.26    2024-03-05 [?] RSPM\n#>  P rnaturalearth * 1.0.1   2023-12-15 [?] RSPM\n#>  P rstudioapi      0.16.0  2024-03-24 [?] RSPM\n#>  P Rttf2pt1        1.3.12  2023-01-22 [?] RSPM\n#>  P sass            0.4.9   2024-03-15 [?] RSPM\n#>  P scales          1.3.0   2023-11-28 [?] RSPM\n#>  P sessioninfo     1.2.2   2021-12-06 [?] RSPM (R 4.4.0)\n#>  P sf            * 1.0-16  2024-03-24 [?] RSPM\n#>  P shiny           1.8.1.1 2024-04-02 [?] RSPM (R 4.4.0)\n#>  P stringi         1.8.3   2023-12-11 [?] RSPM\n#>  P stringr       * 1.5.1   2023-11-14 [?] RSPM\n#>  P styler        * 1.10.3  2024-04-07 [?] RSPM\n#>  P terra           1.7-71  2024-01-31 [?] RSPM\n#>  P tibble        * 3.2.1   2023-03-20 [?] RSPM\n#>  P tidyr         * 1.3.1   2024-01-24 [?] RSPM\n#>  P tidyselect      1.2.1   2024-03-11 [?] RSPM\n#>  P tidyverse     * 2.0.0   2023-02-22 [?] RSPM\n#>  P timechange      0.3.0   2024-01-18 [?] RSPM\n#>  P tzdb            0.4.0   2023-05-12 [?] RSPM\n#>  P units           0.8-5   2023-11-28 [?] RSPM\n#>  P urlchecker      1.0.1   2021-11-30 [?] RSPM (R 4.4.0)\n#>  P usethis         2.2.3   2024-02-19 [?] RSPM (R 4.4.0)\n#>  P utf8            1.2.4   2023-10-22 [?] RSPM\n#>  P vctrs           0.6.5   2023-12-01 [?] RSPM\n#>  P withr           3.0.0   2024-01-16 [?] RSPM\n#>  P xfun            0.43    2024-03-25 [?] RSPM\n#>  P xml2            1.3.6   2023-12-04 [?] RSPM\n#>  P xtable          1.8-4   2019-04-21 [?] RSPM (R 4.4.0)\n#>  P yaml            2.3.8   2023-12-11 [?] RSPM\n#> \n#>  [1] /tmp/RtmpkDFLxI/renv-use-libpath-18824056e1c01e\n#>  [2] /tmp/RtmpkDFLxI/renv-sandbox\n#> \n#>  P â”€â”€ Loaded and on-disk path mismatch.\n#> \n#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n```\n:::\n\n\n</details>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}